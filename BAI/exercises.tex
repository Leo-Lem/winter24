\documentclass{article}

\usepackage[]{../.template/xrcise}

\subject{Bio-inspired Artificial Intelligence}
\semester{Winter 2024}
\author{Leopold Lemmermann}

\begin{document}\createtitle


\sheet{Lecture Questions}
\begin{exercise}{Spiking Neural Networks}
  \begin{enumerate}
    \item Explain the concept of spiking neural networks and how they resemble biological information transmission.
    \item What is the difference between temporal coding and static learning?
    \item How is learning in spiking neural networks based on synaptic correlations?
    \item What is Spike-Timing Dependent Plasticity?
    \item Differentiate rate-coded, integrate-and-fire, and spike-response models.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item Spiking neural networks are a type of artificial neural network that model the behavior of biological neurons. They use spikes, or action potentials, to transmit information between neurons, similar to how biological neurons communicate.
      \item Temporal coding is a method of encoding information in the timing of spikes, while static learning is a method of encoding information in the strength of synaptic connections.
      \item Learning in spiking neural networks is based on synaptic correlations, which are the correlations between the timing of pre- and post-synaptic spikes.
      \item Spike-Timing Dependent Plasticity is a learning rule that strengthens or weakens synaptic connections based on the timing of pre- and post-synaptic spikes.
      \item Rate-coded models use firing rates to encode information, integrate-and-fire models use membrane potentials to encode information, and spike-response models use spike times to encode information.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Computational Neural Networks}
  \begin{enumerate}
    \item Map these biological neural structures to artificial neural networks: neurons/synapses, action potentials, plasticity, and dopamine.
    \item Explain the concept of backpropagation and how it resembles biological plasticity.
    \item Describe two different ANN architectures and their applications.
    \item What are some examples of useful applications of artificial neural networks?
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item Neurons and synapses in biological neural structures correspond to nodes and weighted connections in artificial neural networks. Action potentials in biological neurons correspond to activation values in artificial neural networks. Plasticity in biological synapses corresponds to backpropagation in artificial neural networks. Dopamine in biological reward systems corresponds to reward signals in artificial neural networks.
      \item Backpropagation is a learning algorithm used in artificial neural networks to adjust the weights of connections between neurons based on the error in the output. This process resembles biological plasticity, where synaptic connections are strengthened or weakened based on the correlation between pre- and post-synaptic activity.
      \item Two different ANN architectures are convolutional networks, which are used for image processing tasks, and recurrent networks, which are used for sequential data processing tasks.
      \item Some examples of useful applications of artificial neural networks include speech and language processing, image recognition, and natural language understanding.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Embodied Language Processing}
  \begin{enumerate}
    \item What models are suitable for explaining human natural language processing?
    \item Please explain Hebbian, SOM, and statistical learning.
    \item What is a grounded language?
    \item How can bio-inspired grounded language processing improve classic NLP methods?
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item Models suitable for explaining human natural language processing include sensor to actuator mapping, semantic association, and conceptual representations for stimulus prediction.
      \item Hebbian learning is a learning rule that strengthens synaptic connections between neurons that fire together. SOM learning is a learning algorithm used in self-organizing maps to cluster similar input patterns. Statistical learning is a method of learning from data by estimating the probability distribution of the data.
      \item A grounded language is a language that is based on the physical world and is grounded in sensory-motor experiences.
      \item Bio-inspired grounded language processing can improve classic NLP methods by providing brain-inspired representations and mechanisms that better capture the structure and meaning of language.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Robot Sound Localization}
  \begin{enumerate}
    \item Explain the concepts of ITD and ILD in a hybrid acoustic system.
    \item How can ITD and ILD be implemented in a hybrid spiking neural network?
    \item What are the advantages of this approach?
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item Interaural time difference (ITD) is the difference in time it takes for a sound to reach each ear, while interaural level difference (ILD) is the difference in intensity of a sound at each ear. In a hybrid acoustic system, ITD and ILD are used to localize sound sources in space.
      \item ITD and ILD can be implemented in a hybrid spiking neural network by using spiking neurons to model the auditory pathways and integrating ITD and ILD information to localize sound sources.
      \item The advantages of this approach include the ability to process complex auditory information in real-time, the ability to integrate multiple sensory modalities, and the ability to adapt to changing environments.
    \end{enumerate}
  \end{solution}
\end{exercise}

% Visual information processed in different brain areas
%  Images projected from retina to striate and extrastriate cortex,
% filtered according to different features (edges, orientation, colour,
% motion, …)
%  Visual Processing inspired
% hierarchical computational models for:
% • Object recognition (Fukushima, LeCun)
% • Deep Learning models
\begin{exercise}{}
  % TODO

  \begin{solution}
    % TODO
  \end{solution}
\end{exercise}

% Models for bio-inspired sound source localization, visual
% localization and multisensory integration
%  Multisensory VR environment for neuro-robotic experiments
%  Effectiveness of bio-inspired models
%  Demonstrated behavioral, neurophysiological
% similarity between models and biological systems
\begin{exercise}{}
  % TODO

  \begin{solution}
    % TODO
  \end{solution}
\end{exercise}

% Advantages:
%  Fast Reaction – Immediate mapping of sensory information onto motor actions
%  Robustness – If one part fails, robot may retain some behavioral competence
%  Multiple Goals – Can follow multiple goals simultaneously by combining
% behaviors
%  Extensibility – Easy to add new parts on top of previous
%  Simplicity – Complexity derives from continuous
% interaction of simple modules with environment
% and each other
%  Computational tractability – Usually simple calculations
% and easy to parallelize
%  Development of using LLM for planning
% Disadvantages/Limits:
%  Limited Information – Agents without environment models must have
% sufficient information from local environment
%  Non-Local information – how does agent take into account non-local
% information (e.g. memory?)
%  Learning globally – Difficult to make reactive agents
% that learn global behavior
%  Complex dynamics – It is hard to engineer agents
% with large numbers of behaviors (dynamics of
% interactions become too complex to understand)
\begin{exercise}{}
  % TODO

  \begin{solution}
    % TODO
  \end{solution}
\end{exercise}

% Gestures are an integral part in communication
% • Important in multimodal systems
% • Research on autonomous robots and HRI
%  Model alternatives and choice
% • Dependent on gesture type → gesture continuum
% • Deep networks provide partial solution for feature extraction
% • Recurrent networks in LSTM and GammaGWR
% • Reservoir Computing models by neurophysiological principles
% for action selection in prefrontal cortex and striatum
% • Tradeoff between benchmarking and developing cognitive systems
\begin{exercise}{}
  % TODO

  \begin{solution}
    % TODO
  \end{solution}
\end{exercise}

% Pros:
% • General heuristic for problem search
% • Able to find good solutions in feasible computing time
% • Distributed execution possible
%  Cons:
% • Cannot guarantee optimal solutions
% • Long runtimes, compared to search algorithms
% • Success depends also on used parameters
%  Many further EA approaches: NEAT, HyperNEAT…
\begin{exercise}{}
  % TODO

  \begin{solution}
    % TODO
  \end{solution}
\end{exercise}

%  LMM deliver pointwise understanding for frequent cases
%  For rare cases LMM often “autocorrect reality” answering often wrong question
%  Hybrid systems make complementary use of symbolic and connectionist AI
%  Symbolic rules can be extracted from neural networks
%  Different architectures for integrating symbolic and neural computing are
% possible
%  How images are processed by a neural network can be visualized
%  Hybrid systems and explainable AI are in the
% current focus of research
%  Topics for thesis, independent studies, etc.
\begin{exercise}{}
  % TODO

  \begin{solution}
    % TODO
  \end{solution}
\end{exercise}

\sheet[2023]{1st exam}

\begin{exercise}{Multiple Choice}
  \begin{enumerate}
    \item The neighborhood in a self-organizing map (SOM) is computed as a 
      \begin{itemize}
        \item Gaussian
        \item linear
        \item step
        \item constant
      \end{itemize}
      function of the distance between the winning neuron and the other neurons.

    \item A ground language is based on the 
      \begin{itemize}
        \item ground truth.
        \item physical world.
        \item ground state.
        \item ground floor.
      \end{itemize}

    \item The ventriloquism effect is the illusion that a sound is coming from 
      \begin{itemize}
        \item a different location
        \item the same Location
      \end{itemize}
      than the actual source.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item Gaussian.
      \item Physical world.
      \item A different location.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{General}
  \begin{enumerate}
    \item Explain the multisensory integration of different strength stimuli.
    \item What is the cocktail party effect?
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item Multisensory integration is the process by which information from different sensory modalities is combined to form a unified percept. This process can enhance the detection and discrimination of stimuli and improve the accuracy and reliability of sensory processing.
      \item The cocktail party effect is the ability to focus on a single conversation in a noisy environment. This phenomenon allows individuals to selectively attend to one speaker while ignoring other competing sounds.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Spiking Neural Networks}
  \begin{enumerate}
    \item Explain the difference between the leaky integrate-and-fire model and the integrate-and-fire model.
    \item Calculate the similarity angle between a weight vector $\mathbf{w} = [1, 2, 3]$ and an input vector $\mathbf{x} = [4, 5, 6]$.
    \item Compute the output of a perceptron with weights $\mathbf{w} = [1, 2, 3]$ and input $\mathbf{x} = [4, 5, 6]$.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item In the integrate-and-fire model, the neuron integrates input signals over time and fires a spike when the membrane potential reaches a threshold. In the leaky integrate-and-fire model, the neuron also integrates input signals over time, but the membrane potential decays over time in the absence of input. This leads to more realistic behavior and allows the neuron to adapt to changing input conditions.
      \item The similarity angle between two vectors $\mathbf{a}$ and $\mathbf{b}$ is given by
        \[ \cos(\theta) = \frac{\mathbf{a} \cdot \mathbf{b}}{\|\mathbf{a}\| \|\mathbf{b}\|}. \]
        For $\mathbf{w} = [1, 2, 3]$ and $\mathbf{x} = [4, 5, 6]$, we have
        \[ \cos(\theta) = \frac{1 \cdot 4 + 2 \cdot 5 + 3 \cdot 6}{\sqrt{1^2 + 2^2 + 3^2} \sqrt{4^2 + 5^2 + 6^2}} = \frac{32}{\sqrt{14} \sqrt{77}}. \]
      \item The output of a perceptron is given by
        \[
          y = \begin{cases}
            1 & \text{if } \mathbf{w} \cdot \mathbf{x} > 0, \\
            0 & \text{otherwise}.
          \end{cases}
        \]
        For $\mathbf{w} = [1, 2, 3]$, $\mathbf{x} = [4, 5, 6]$, and $b = 0$, we have
        \[
          y = \begin{cases}
            1 & \text{if } 1 \cdot 4 + 2 \cdot 5 + 3 \cdot 6 > 0, \\
            0 & \text{otherwise}.
          \end{cases}
        \]
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Visual Processing}
  \begin{enumerate}
    \item What do the different layers in a convolutional neural network (CNN) learn?
    \item Compute the filtering in a CNN layer with a $5 \times 5$ matrix and a $3 \times 3$ filter, stride $1$, and no padding.
    \item Draw a diagram of the orientation and firing rate of a simple cell for a line of different orientations.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item The different layers in a CNN learn different features of the input data. The first layers typically learn low-level features like edges and textures, while later layers learn higher-level features like shapes and objects.
      \item The filtering in a CNN layer with a $5 \times 5$ matrix and a $3 \times 3$ filter, stride $1$, and no padding can be computed by sliding the filter over the input matrix and computing the dot product at each position. The resulting output will be a $3 \times 3$ matrix.
      \item The orientation and firing rate of a simple cell for a line of different orientations can be visualized in a diagram with the orientation on the $x$-axis and the firing rate on the $y$-axis. It usually shows a peak at the preferred orientation of the cell and decreases for other orientations.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Audio Processing}
  Explain interaural time difference (ITD) and interaural level difference (ILD) and which one is used for high and low frequencies.

  \begin{solution}
    \begin{enumerate}
      \item Interaural time difference (ITD) is the difference in time it takes for a sound to reach each ear, while interaural level difference (ILD) is the difference in intensity of a sound at each ear. ITD is used for low frequencies, while ILD is used for high frequencies.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Behavior}
  \begin{enumerate}
    \item Explain a Braitenberg vehicle with an example and name the behavior of your example vehicle.
    \item Complete the flow chart of the functional decomposition of the classical approach for a robot controller: sensors $\rightarrow$ \_ $\rightarrow$ \_ $\rightarrow$ \_ $\rightarrow$ \_ $\rightarrow$ actuators.
    \item Explain the advantage of a behavior-based approach to robotics.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item A Braitenberg vehicle is a simple robot that exhibits complex behavior through the direct coupling of sensors to actuators. An example of a Braitenberg vehicle is a light-seeking robot that moves towards a light source. The behavior of this example vehicle is phototaxis.
      \item The flow chart of the functional decomposition of the classical approach for a robot controller is: sensors $\rightarrow$ perception $\rightarrow$ modelling $\rightarrow$ planning $\rightarrow$ execution $\rightarrow$ actuators.
      \item The advantage of a behavior-based approach to robotics is that it allows for the development of complex behaviors through the combination of simple behaviors. This approach is more robust and adaptable to changing environments than traditional control architectures.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Evolutionary Computing}
  \input{res/tsp.fig}

  \begin{enumerate}
    \item Draw a cycle graph with the nearest-neighbor heuristic for the traveling salesman problem.
    \item Find the shortest distance between city $1$ and city $4$ in the graph.
    \item Describe a recombination and mutation algorithm for the example you provided.
    \item Explain optimization strategies for this algorithm.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item A cycle graph with arrow labels is a graph where each node is connected to the next node in a cycle, and the arrows indicate the direction of the cycle.
      \item The shortest distance between city $1$ and city $4$ in the graph is $1\to3\to4$.
      \item An approach to solving the traveling salesman problem using recombination and mutation could involve combining the paths of two solutions to create a new solution and randomly swapping cities in the solution to introduce diversity.
      \item Optimization strategies for this algorithm could include using a genetic algorithm to evolve a population of solutions, using local search to improve the quality of solutions, and using elitism to preserve the best solutions.
    \end{enumerate}
  \end{solution}
\end{exercise}



\sheet[2022]{1st exam}

\begin{exercise}{Multiple Choice}
  \begin{enumerate}
    \item In which models is backpropagation used for learning?
      \begin{itemize}
        \item Multilayer perceptron (MLP)
        \item Convolutional neural network (CNN)
        \item Self-organizing map (SOM)
        \item None of the above
      \end{itemize}

    \item What does "embodied" mean for language?
      \begin{itemize}
        \item Language is based on the physical world.
        \item Language is based on the ground truth.
        \item Language is based on the ground state.
        \item Language is based on the ground floor.
      \end{itemize}

    \item What are the two streams and their tasks in human vision?
      \begin{itemize}
        \item Dorsal stream for spatial vision and ventral stream for object recognition
        \item Ventral stream for spatial vision and dorsal stream for object recognition
        \item Dorsal stream for object recognition and ventral stream for spatial vision
        \item Ventral stream for object recognition and dorsal stream for spatial vision
      \end{itemize}
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item Multilayer perceptron (MLP)
      \item Language is based on the physical world.
      \item Dorsal stream for spatial vision and ventral stream for object recognition
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Attention}
  \begin{enumerate}
    \item Name and explain three ways to measure the attention of a human.
    \item Describe two models to measure or visualize human attention.
    \item Name advantages and disadvantages of the two models you proposed.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item Three ways to measure the attention of a human are eye tracking, reaction time, and brain imaging.
      \item Two models to measure or visualize human attention are the spotlight model and the zoom lens model.
      \item The spotlight model has the advantage of being simple and intuitive, but it has the disadvantage of oversimplifying the attentional process. The zoom lens model has the advantage of being more flexible and dynamic, but it has the disadvantage of being more complex and difficult to interpret.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Vision}
  \begin{enumerate}
    \item Name the two streams and their task that are present in human vision.
    \item Explain rods and cones.
    \item Explain the similarity between a convolutional neural network with convolution and max pooling layers and the visual cortex.
    \item Visualize the firing rate of a simple cell for a line of different orientation in a diagram with the orientation on the $x$-axis and the firing rate on the $y$-axis.
    \item Given a $5 \times 5$ matrix and a $3 \times 3$ filter, compute the convolution (no padding, stride $1$).
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item The two streams present in human vision are the dorsal stream for spatial vision and the ventral stream for object recognition.
      \item Rods and cones are photoreceptor cells in the retina that are responsible for detecting light. Rods are sensitive to low light levels and are responsible for night vision, while cones are sensitive to color and are responsible for daylight vision.
      \item A convolutional neural network with convolution and max pooling layers is similar to the visual cortex in that both systems use hierarchical processing to extract features from the input data.
      \item The firing rate of a simple cell for a line of different orientations can be visualized in a diagram with the orientation on the $x$-axis and the firing rate on the $y$-axis.
      \item Given a $5 \times 5$ matrix and a $3 \times 3$ filter, the convolution (no padding, stride $1$) can be computed by sliding the filter over the input matrix and computing the dot product at each position. The resulting output will be a $3 \times 3$ matrix.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Sound Localization}
  \begin{enumerate}
    \item Compute the cross-correlation steps on two signals until the maximum cross-correlation value is reached.
    \item Name and explain the two cues used to perform sound localization. Which one works best for high/low frequencies?
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item The cross-correlation steps on two signals can be computed by sliding one signal over the other and computing the dot product at each position until the maximum cross-correlation value is reached.
      \item The two cues used to perform sound localization are interaural time difference (ITD) and interaural level difference (ILD). ITD works best for low frequencies, while ILD works best for high frequencies.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Behavior}
  \begin{enumerate}
    \item Explain a Braitenberg vehicle with an example and name the behavior of your example vehicle.
    \item Complete the flow chart of the functional decomposition of the classical approach for a robot controller: sensors $\rightarrow$ blank $\rightarrow$ blank $\rightarrow$ blank $\rightarrow$ blank $\rightarrow$ actuators.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item A Braitenberg vehicle is a simple robot that exhibits complex behavior through the direct coupling of sensors to actuators. An example of a Braitenberg vehicle is a light-seeking robot that moves towards a light source. The behavior of this example vehicle is phototaxis.
      \item The flow chart of the functional decomposition of the classical approach for a robot controller is: sensors $\rightarrow$ perception $\rightarrow$ cognition $\rightarrow$ planning $\rightarrow$ control $\rightarrow$ actuators.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Continual Learning}
  \begin{enumerate}
    \item Explain the stability-plasticity dilemma.
    \item Explain catastrophic forgetting and a model where this effect could arise.
    \item Name and describe two strategies of continual learning.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item The stability-plasticity dilemma is the trade-off between the ability of a neural network to learn new information (plasticity) and the ability of the network to retain previously learned information (stability).
      \item Catastrophic forgetting is the phenomenon where a neural network forgets previously learned information when learning new information. This effect could arise in a model where the network is trained on a sequence of tasks without preserving the knowledge learned on previous tasks.
      \item Two strategies of continual learning are rehearsal, where the network is periodically trained on previously learned tasks, and regularization, where the network is penalized for changing its weights too much.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Language Processing}
  \begin{enumerate}
    \item Name the two streams important in language processing and their tasks.
    \item Describe CBOW (Continuous Bag-of-word) and Skip-gram.
    \item Describe the difference between the earlier Wernicke's model and the later Pulvermüller's model.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item The two streams important in language processing are the dorsal stream for speech perception and the ventral stream for speech production.
      \item CBOW (Continuous Bag-of-word) and Skip-gram are two models used for word embedding in natural language processing. CBOW predicts a target word from its context, while Skip-gram predicts the context words from a target word.
      \item The difference between the earlier Wernicke's model and the later Pulvermüller's model is that Wernicke's model is based on a sequential processing model of language, while Pulvermüller's model is based on a distributed processing model of language.
    \end{enumerate}
  \end{solution}
\end{exercise}

\begin{exercise}{Computational Neural Networks}
  \begin{enumerate}
    \item Explain three steps of the backpropagation algorithm and explain the termination criteria.
    \item Name and shortly describe the three fundamental ANN learning paradigms.
    \item Explain how the learning rate parameter could be chosen.
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item Three steps of the backpropagation algorithm are forward propagation, backward propagation, and weight update. The termination criteria for backpropagation is typically based on the convergence of the loss function.
      \item The three fundamental ANN learning paradigms are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves learning from labeled data, unsupervised learning involves learning from unlabeled data, and reinforcement learning involves learning from rewards and punishments.
      \item The learning rate parameter could be chosen using a grid search or random search over a range of values, or by using adaptive learning rate methods like AdaGrad or Adam.
    \end{enumerate}
  \end{solution}
\end{exercise}

\end{document}